{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "490479e3-0601-43e6-8d61-d2c16a6769db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch main\n",
      "Your branch is up to date with 'origin/main'.\n",
      "\n",
      "Changes not staged for commit:\n",
      "  (use \"git add <file>...\" to update what will be committed)\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\n",
      "\tmodified:   environment.yml\n",
      "\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c49ea1-3c9d-412a-8e42-141c1c24a10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add .\n",
    "!git commit -m \"Add Pandas dep\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d700b9c7-ce5c-447d-8fca-fd0fb4817a0d",
   "metadata": {},
   "source": [
    "# Distinguishing tiles in one's pocket from tiles in the wild\n",
    "\n",
    "Here's the challenge: Person X goes on a walk in the city, carrying a tile, and also a tile signal collector. X's tile rotates between a finite set of keys. X will obviously capture their own signal -- a certain number of *beacons* for each of the keys their tile is going through. They will also capture beacons from tiles in the pockets and bags of people they walk by. How can X distinguish the keys beaconed out of their tile from those of other people?\n",
    "\n",
    "One would think that the sustained proximity between the person's own tile and their detector will make it so the largest **number of beacons collected** should be for their own keys. However, this is a poor decision variable, as it depends on the number of keys being rotated through, as well as the beacon frequency for the tile. Some brands of tiles might send beacons at much higher frequencies, making beacon numbers an imprecise appreciation of key ownership. A much better variable to test over should be **signal strength** (as measured in decibels): since X's own tile will always be closer to the detector than other people's, we should see an appreciably stronger signal from the former than from the latter.\n",
    "\n",
    "Let's test this hypothesis from an early dataset we collected, where X's tile is an Apple AirTag that rotates between 4 keys."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f37c37-3981-4ca6-aaec-c2f6449646ea",
   "metadata": {},
   "source": [
    "---\n",
    "## Accessing and loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfc0172-3294-40db-86ee-b09413abf56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a666a2-9549-43c5-84e8-9b76fb99474a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fsspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61a9317-bb91-4465-b9a6-d5151738880c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = fsspec.filesystem(\"abfs\")\n",
    "CONTAINER = \"team1-3\"\n",
    "fs.ls(CONTAINER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bffa28-8ea8-4937-8715-0c53e2ad8d11",
   "metadata": {},
   "source": [
    "The files involved in this experiment are `April9DataOnly.txt`, which contains recorded beacons, and `April9MyAirtagRotatingKeys.txt`, which contains only beacons from X's tile. This last file is thus the ground truth: let's try and use the assumptions above to guess the 4 keys of X's tile.\n",
    "\n",
    "What does the data file look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c40aeeb-cc11-48ca-9744-c9731449d858",
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_blob(path):\n",
    "    return f\"{CONTAINER}/{path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ac2651-5006-4cef-906f-90e016db137e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.head(path_blob(\"April9DataOnly.txt\"), 4096)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b495d95e-dba8-4f9d-a235-43567e8122aa",
   "metadata": {},
   "source": [
    "It's hard to eyeball, but this is a text file. On each line lives what looks like a Python dictionary. It looks like JSON too, but JSON is double-quoted, never single-quoted; we can't rely on Python's strict JSON decoders to help us here.\n",
    "\n",
    "Fortunately, there is a safe way to interpret Python dictionary literals, using Python's embedded compiler front-end through the `ast` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fe840e-329e-4386-b498-144eb1b639d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "\n",
    "\n",
    "def read_dict_stream(path):\n",
    "    with fs.open(path_blob(path), mode=\"r\", encoding=\"utf-8\") as file:\n",
    "        return pd.DataFrame([ast.literal_eval(line) for line in tqdm_notebook(file)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b130748-614d-4481-b662-c648b8ef94c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_dict_stream(\"April9DataOnly.txt\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dee22d-3f6a-42bb-a3d1-3349bdf69c61",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## From beacons to keys\n",
    "\n",
    "So we have some 20k beacon records, for each of which we have signal strength written up in the `rssi` column. While a more thorough analysis of the semantics of this dataset would be useful, let's focus on our purpose for the time being. For each key, we want to capture aggregate statistics of the beacons we captured for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdc6699-7752-4a7f-bc84-1d3555a66316",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_raw = df.groupby(\"manufacturerDataHex\").agg({\"rssi\": [\"count\", \"mean\", \"std\", \"min\", \"max\"]})\n",
    "keys_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535327c9-18de-4e56-bbff-04678712d27d",
   "metadata": {},
   "source": [
    "So we have beacons for 1379 distinct keys. The number of beacons recorded for each key seems to vary quite a bit. We also see some variation in the dynamic range of the signal strength (the gap between minimal and maximal recorded signal strength). Let's take a look at the distribution of beacon counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d297572-322a-41fa-83cb-535de0942433",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d349558d-40c3-4b6f-a9be-6620b9d8eecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_raw[(\"rssi\", \"count\")].hist(bins=[0, 10, 20, 50, 100, 200, 300, 400])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477760de-6aae-4b99-8822-ac66ac934384",
   "metadata": {},
   "source": [
    "So for most of these keys (more than 1000 out of our 1379), we have 10 keys or less; these cannot possibly be X's keys. As flawed as this decision variable is, given that X has probably *not* been sticking their bodies very close to strangers' throughout their errand, we would still find their keys among those in some top-$N$ of the counts. Let's try the top-50 to start with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf1fd1e-6e8e-49ce-8e59-e0dd71216d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_top50 = keys_raw.sort_values((\"rssi\", \"count\"), ascending=False).head(50)\n",
    "keys_top50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e908dc9d-1923-4fe4-ae90-830f43c7d009",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Estimating average signal strength \n",
    "\n",
    "For each of these keys, we have between 111 and 372 beacons, each carrying its own measure of the signal strength. Thus, to assess a key's signal strength, we must proceed by *estimation*. It is not unreasonable to assume that our signal strength measures are *independant*. As such, the **average signal strength** associated to any key can be derived using the central limit theorem (involving Student's $t$ distribution as well as the mean and standard deviation), guiding us to build a confidence interval for each key. The following does this tersely, using a confidence level of 0.95."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a6f486-f9d0-47c5-984e-9233661e8328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "alpha = 1 - 0.95\n",
    "ic = pd.DataFrame(\n",
    "    np.outer(keys_top50[(\"rssi\", \"mean\")], [1, 1]) + np.outer(\n",
    "        (\n",
    "            stats.t(df=keys_top50[(\"rssi\", \"count\")] - 1).ppf(1 - alpha / 2)\n",
    "            * keys_top50[(\"rssi\", \"std\")]\n",
    "            / np.sqrt(keys_top50[(\"rssi\", \"count\")])\n",
    "        ),\n",
    "        [-1., 1.]\n",
    "    ),\n",
    "    index=keys_top50.index,\n",
    "    columns=[\"lower\", \"upper\"]\n",
    ")\n",
    "ic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28791dc7-6140-42e3-ad2b-90a1a518135d",
   "metadata": {},
   "source": [
    "Let's visualize these confidence intervals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6359ea8-a6e0-4d13-af7b-a46aca37ff5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.arange(len(keys_top50))\n",
    "plt.plot(x, ic[\"lower\"], 'bv', x, ic[\"upper\"], 'b^')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f75e67-25ed-41dd-b43b-21c4630072d5",
   "metadata": {},
   "source": [
    "I'm used to estimation jobs that involve tricky comparisons -- this one is *not tricky at all*. The assumption behind signal strength as a decision key for tile ownership is verified. We see that the keys for X's tile report signal strengths well above -50, while _every_ other one runs below this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b47e230-5682-4c63-9431-7c0bde8730af",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, ic[\"lower\"], 'bv', x, ic[\"upper\"], 'b^')\n",
    "plt.plot(x, -50 * np.ones(x.shape), 'r--')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49397473-3487-4a87-be64-d3d4ecd086c1",
   "metadata": {},
   "source": [
    "Let's thus use this as decision threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08f7d2a-72ca-4768-ac02-678042c84af8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Have we found the keys?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f622d0-be7b-4526-abc5-ade328a7f9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_x = keys_top50.loc[ic[\"lower\"] > -50.]\n",
    "answer = set(keys_x.index)\n",
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5c7e88-fd21-44d7-90f0-4dfac253dfda",
   "metadata": {},
   "source": [
    "Now, let's compare with the ground truth..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e701a1-2a40-41cb-ba6e-883ad30b0581",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = set(read_dict_stream(\"April9MyAirtagRotatingKeys.txt\").manufacturerDataHex)\n",
    "if answer == ground_truth:\n",
    "    print(\"üç∞\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0257d7ae-1acb-4698-95d9-f30f80da92b6",
   "metadata": {},
   "source": [
    "Yay, cake!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce68da71-60af-4b10-b26a-e9e207548bc4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## The beacon count assumption\n",
    "\n",
    "We had initially dismissed that the keys associated to the largest numbers of captured beacons would be ours. Let's compare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a65ddbf-1070-4d8e-a46e-c9ae201d5db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a143b0f0-4aab-4547-b2ff-c73dd5f29625",
   "metadata": {},
   "source": [
    "These are emphatically not the largest-count keys we got. Actually, the last one comes in position 50, at the very bottom of the top-50 we analyzed. Yes, understanding that each key is beaconed out of the same tile, we get that X's tile is the one for which we have the most beacons. However, the split of X's beacon set between the keys is playing an important role in weakening beacon counts as ownership indicators. If somebody enlarges their tile's key set further, their per-key beacon counts will likely even drop out of the top quantiles, making this top-$N$ filtering actually impair the truth of their analysis. It's signal strength that decides, not beacon counts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fbd893-3076-49e7-81d4-ed46d37dce7d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Some extra-curricular work: the distribution of signal strength\n",
    "\n",
    "Let's compare signal strength distribution for X's own 4 keys to those X captured in the wild."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f06ec1b-89ae-48ed-a387-fc6399afc067",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "for i, key in enumerate(answer, start=1):\n",
    "    plt.subplot(1, 4, i)\n",
    "    df.loc[df.manufacturerDataHex == key].rssi.hist(bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e37346-b765-4e2a-9faf-8d56e6ecdf6c",
   "metadata": {},
   "source": [
    "We observe that the assumption that drove our estimation of signal strength on the basis of the distribution being _central_ is flawed: the distribution of the best signals we've captured is actually skewed left, that would probably be better modeled using a Weibull distribution. It makes obvious that even when signal should be strong, it is _quite_ likely to get a baseline-weak measurement, whereas the signal strength is likely capped by some physical constraint on the good end.\n",
    "\n",
    "What about the highest-count and lowest-count keys not belong to X?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9abe0d3-0f07-4225-b5b4-23ed7e98d942",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_most_beacons = [\n",
    "    \"4c00121900dee4cd376ddaf94db04e7dd3970e5560f90670b8a6840200\",\n",
    "    \"4c0012190029f866de8e804ea0c8307ed030efb5f3e1895eff29130100\",\n",
    "    \"4c001219007d891055838ac76a6e2d82a7e4019ad4d682cdf93b540100\",\n",
    "    \"4c00121900fc3e5d40d6c9549bb10b2b6465c7cb90685cd44945ee0000\"\n",
    "]\n",
    "keys_least_beacons = [\n",
    "    \"4c001219005d187ef77a26ac4bde0c17865cb2f1660d4634b605db0200\",\n",
    "    \"4c00121900788e06e8affb2fa49f373c57d68f0e6d63e0918a37a90100\",\n",
    "    \"4c00121900abf6fa47fa46f9a32c160f5152f124bb593e73442b5f0300\",\n",
    "    \"4c00121900b761fee7b5eaacc0c74f77eeccb7de49015e9b98092e0000\"\n",
    "]\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, key in enumerate(keys_most_beacons + keys_least_beacons, start=1):\n",
    "    plt.subplot(2, 4, i)\n",
    "    df.loc[df.manufacturerDataHex == key].rssi.hist(bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee96d0dc-82f2-4f4f-9290-cb1dd6cb654e",
   "metadata": {},
   "source": [
    "For these significantly weaker signals, the centrality of the distribution tends to be quite better. The many-beacons cases of the top row show a less noisy picture than the less-beacons cases of the bottom row, which is a normal phenomenon bound to data quantity. So it seems that the leftward skew of the strong signals is effectively due to a natural device characteristic: we get the best possible signal strength in most cases, so all the variation comes on the lossy side."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iot-hunters (Python)",
   "language": "python",
   "name": "conda-env-iot-hunters-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
